{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PYEVALB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk import Tree, grammar\n",
    "import random\n",
    "import queue\n",
    "import pickle as pkl\n",
    "from scipy.spatial import distance\n",
    "from PYEVALB import scorer\n",
    "from PYEVALB import parser\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import math\n",
    "from itertools import product\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sequoia-corpus+fct.mrg_strict', 'r', encoding = 'utf-8') as file:\n",
    "    data = file.read().splitlines()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_functional_labels(string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ----------------\n",
    "    Ignore functional labels in the non terminals of a rule, for example PP-MOD becomes PP\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    string : String form of parse tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    new string form of parse tree\n",
    "    \"\"\"\n",
    "    \n",
    "    l = string.split(' ')[1:]\n",
    "    for i in range(len(l)):\n",
    "        if l[i][0] == '(':\n",
    "            l[i] = l[i].split('-')[0]\n",
    "            \n",
    "    return ' '.join(l)[:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes(rule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Extract the non terminal and terminal nodes from a rule along with the status of the rule (either lexical 1, or not 0)\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    rule : nltk.grammar.Production object, the rule to consider.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    3-tuple, tuple[0] : the lexical status.\n",
    "             tuple[1] : set containing the non terminal nodes.\n",
    "             tuple[2] : set containing the terminal nodes.\n",
    "    \"\"\"\n",
    "    if rule.is_lexical():\n",
    "        return True, set((rule._lhs._symbol,)), set((rule._rhs))\n",
    "    \n",
    "    else:\n",
    "        return False, set((rule._lhs._symbol,)).union(set((rule._rhs[0]._symbol, rule._rhs[1]._symbol))), set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[9*len(data)//10:]\n",
    "data = data[:9*len(data)//10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_terminals = set()\n",
    "pos_tags = set()\n",
    "terminals = set()\n",
    "binaries = set()\n",
    "starts = set()\n",
    "for string in data:\n",
    "    t = Tree.fromstring(ignore_functional_labels(string))\n",
    "    t.chomsky_normal_form(horzMarkov=2)\n",
    "    t.collapse_unary(collapsePOS=True, collapseRoot=True)\n",
    "    rules = t.productions()\n",
    "    starts.add(rules[0]._lhs._symbol)\n",
    "    for rule in rules:\n",
    "        lexical, non_terminal_nodes, terminal_nodes = extract_nodes(rule)\n",
    "        if lexical:\n",
    "            non_terminals = non_terminals.union(non_terminal_nodes)\n",
    "            pos_tags = pos_tags.union(non_terminal_nodes)\n",
    "            terminals = terminals.union(terminal_nodes)\n",
    "            \n",
    "        else:\n",
    "            non_terminals = non_terminals.union(non_terminal_nodes)\n",
    "            if len(rule._rhs) == 2:\n",
    "                binaries.add((rule._rhs[0]._symbol, rule._rhs[1]._symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SENT',\n",
       " 'SENT+AP',\n",
       " 'SENT+AP+ADJ',\n",
       " 'SENT+COORD',\n",
       " 'SENT+NC',\n",
       " 'SENT+NP',\n",
       " 'SENT+NP+NC',\n",
       " 'SENT+NP+NPP',\n",
       " 'SENT+NPP',\n",
       " 'SENT+PONCT',\n",
       " 'SENT+PP',\n",
       " 'SENT+VPinf'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terminals : 9632\n",
      "Number of POS tags : 60\n",
      "Number of non terminals : 832\n",
      "Number of binaries : 2640\n"
     ]
    }
   ],
   "source": [
    "print('Number of terminals : %d' %len(terminals))\n",
    "print('Number of POS tags : %d' %len(pos_tags))\n",
    "print('Number of non terminals : %d' %len(non_terminals))\n",
    "print('Number of binaries : %d' %len(binaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_non_terminals_indices = {non_terminal : index for index, non_terminal in enumerate(non_terminals)}\n",
    "dict_indices_non_terminals = {index : non_terminal for non_terminal, index in dict_non_terminals_indices.items()}\n",
    "\n",
    "dict_pos_indices = {pos : index for index, pos in enumerate(pos_tags)}\n",
    "dict_indices_pos = {index : pos for pos, index in dict_pos_indices.items()}\n",
    "\n",
    "dict_terminals_indices = {terminal : index for index, terminal in enumerate(terminals)}\n",
    "dict_indices_terminals = {index : terminal for terminal, index in dict_terminals_indices.items()}\n",
    "\n",
    "dict_binaries_indices = {binary : index for index, binary in enumerate(binaries)}\n",
    "dict_indices_terminals = {index : binary for binary, index in dict_binaries_indices.items()}\n",
    "\n",
    "dict_starts_indices = {binary : index for index, binary in enumerate(starts)}\n",
    "dict_indices_starts = {index : binary for binary, index in dict_starts_indices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def express_node(rule):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Express the nature of the rule and extract its left hand and right hand sides.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    rule : nltk.grammar.Production object, the rule to consider.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    3-tuple, tuple[0] : String describing the rule {'lexical', 'start_node', 'unary', 'binary'}\n",
    "             tuple[1] : nltk.grammar.Production, the left hand side of the rule.\n",
    "             tuple[2] : nltk.grammar.Production, the right hand side of the rule.\n",
    "    \"\"\"\n",
    "    if rule.is_lexical():\n",
    "        return 'lexical', rule._lhs._symbol, rule._rhs[0]\n",
    "    \n",
    "    else:\n",
    "        lhs, rhs = rule._lhs._symbol, (rule._rhs[0]._symbol, rule._rhs[1]._symbol)\n",
    "        if len(rhs) == 2:\n",
    "            return 'binary', lhs, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcfg(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ----------------\n",
    "    Create PCFG model from the data, i.e compute the probability of each rule (conditiona probabilities) statistically from the data\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    data : List of strings representing parse trees.\n",
    "    \n",
    "    Returns\n",
    "    ----------------\n",
    "    dict_pcfg   : Dictionnary with three keys {'lexical', 'unary', 'binary'}\n",
    "                 - dict_pcfg['lexical']  : dictionnary of lexicons.\n",
    "                                           - keys   : POS tags; \n",
    "                                           - values : dictionnary of probabilities p(terminal|POS_tag)\n",
    "                                                     - keys   : terminals.\n",
    "                                                     - values : p(terminal|POS_tag)\n",
    "                 - dict_pcfg['unary']    : dictionnary of unary laws.\n",
    "                                           - keys   : non terminals; \n",
    "                                           - values : dictionnary of probabilities p(node|non_terminal), node here can be\n",
    "                                                      either a POS tag or a non terminal.\n",
    "                                                     - keys   : non terminals.\n",
    "                                                     - values : p(node|non_terminal)\n",
    "                                                                          \n",
    "                 - dict_pcfg['binary']   : dictionnary of binary laws.\n",
    "                                           - keys   : non terminals; \n",
    "                                           - values : dictionnary of probabilities p(node|non_terminal), node here is binary\n",
    "                                                      containing POS tags or non terminals.\n",
    "                                                     - keys   : non terminals.\n",
    "                                                     - values : p(node|non_terminal)\n",
    "                                                                        \n",
    "    dict_probas : Dictionnary rearranging the elements of dict_pcfg in a way that simplifies the use of the probabilities \n",
    "                  in the CYK algorithm, keys in {'lexical', 'unary', 'binary'}                  \n",
    "                  dictionnary of probabilities.\n",
    "                            - keys   : unary nodes (POS tags or non terminals).\n",
    "                            - values : probabilities p(node|unary_node)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initalize dictionnaries dict_lexicons, dict_unaries, dict_binaries that we put in dict_pcfg\n",
    "    dict_lexicons, dict_binaries = {}, {}\n",
    "    dict_pcfg = {'lexical' : dict_lexicons, 'binary' : dict_binaries}\n",
    "    \n",
    "    # Loop over the data\n",
    "    for string in data:\n",
    "        t = Tree.fromstring(ignore_functional_labels(string)) # Ignore the functional labels (see the doc of ignore_functional_labels)\n",
    "        t.chomsky_normal_form(horzMarkov=2)  # Convert the tree to Chomsky normal form\n",
    "        t.collapse_unary(collapsePOS=True, collapseRoot=True)\n",
    "        rules = t.productions()  # Get the rules\n",
    "        for rule in rules:       # We start by counting the rules in data\n",
    "            nature, lhs, rhs = express_node(rule)\n",
    "            if lhs in dict_pcfg[nature]:\n",
    "                if rhs in dict_pcfg[nature][lhs]:\n",
    "                    dict_pcfg[nature][lhs][rhs] += 1\n",
    "\n",
    "                else:\n",
    "                    dict_pcfg[nature][lhs][rhs] = 1\n",
    "\n",
    "            else:\n",
    "                dict_pcfg[nature][lhs] = {rhs : 1}\n",
    "                \n",
    "    dict_normalized = {}\n",
    "    for nature in dict_pcfg:\n",
    "        for lhs in dict_pcfg[nature]:\n",
    "            if lhs in dict_normalized:\n",
    "                dict_normalized[lhs] += sum(dict_pcfg[nature][lhs].values())\n",
    "                \n",
    "            else:\n",
    "                dict_normalized[lhs] = sum(dict_pcfg[nature][lhs].values())\n",
    "                \n",
    "    for nature in dict_pcfg:\n",
    "        for lhs in dict_pcfg[nature]:\n",
    "            dict_pcfg[nature][lhs] = dict((key, value/dict_normalized[lhs]) for key, value in dict_pcfg[nature][lhs].items())\n",
    "\n",
    "    dict_probas = {'lexical' : {}, 'unary' : {}, 'binary' : {}} # Initialize dict_probas\n",
    "    for nature in dict_pcfg:\n",
    "        for lhs in dict_pcfg[nature]:\n",
    "            for node in dict_pcfg[nature][lhs]:\n",
    "                if node in dict_probas[nature]:\n",
    "                    dict_probas[nature][node][lhs] = math.log(dict_pcfg[nature][lhs][node])\n",
    "\n",
    "                else:\n",
    "                    dict_probas[nature][node] = {lhs : math.log(dict_pcfg[nature][lhs][node])}\n",
    "                    \n",
    "    return dict_pcfg, dict_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pcfg, dict_probas = pcfg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9632"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_probas['lexical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_probas['binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CYK algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_binary, C_binary = set([binary[0] for binary in dict_probas['binary'].keys()]), set([binary[1] for binary in dict_probas['binary'].keys()])\n",
    "set_binary = set(dict_probas['binary'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyk(sentence):\n",
    "    \n",
    "    n = len(sentence) + 1\n",
    "    k = len(non_terminals)\n",
    "    scores = [[{} for j in range(n)] for l in range(n)]\n",
    "    back = [[[None for i in range(k)] for j in range(n)] for l in range(n)]\n",
    "    Bs_scores, Cs_scores = [[set() for j in range(n)] for l in range(n)], [[set() for j in range(n)] for l in range(n)]\n",
    "    for i in range(0, n-1):\n",
    "        word = sentence[i]\n",
    "        if word in dict_probas['lexical'].keys():\n",
    "            for A in dict_probas['lexical'][word]:\n",
    "                scores[i][i+1][A] = dict_probas['lexical'][word][A]\n",
    "                if A in B_binary:\n",
    "                    Bs_scores[i][i+1].add(A)\n",
    "\n",
    "                if A in C_binary:\n",
    "                    Cs_scores[i][i+1].add(A)\n",
    "                    \n",
    "        else:\n",
    "            print(word + \" : isn't in terminals\")\n",
    "            return scores, back\n",
    "                 \n",
    "    for span in range(2, n):\n",
    "        start_time_binary = time()\n",
    "        for begin in range(0, n-span):\n",
    "            end = begin + span\n",
    "            start_time_binary = time()\n",
    "            for split in range(begin+1, end):\n",
    "                Bs = Bs_scores[begin][split].intersection(B_binary)\n",
    "                Cs = Cs_scores[split][end].intersection(C_binary)\n",
    "                \n",
    "                for B, C in set_binary.intersection(set(product(Bs, Cs))):\n",
    "                    score_B, score_C = scores[begin][split].get(B, -np.inf), scores[split][end].get(C, -np.inf)\n",
    "                    for A in dict_probas['binary'][(B, C)]:\n",
    "                        prob = score_B + score_C + dict_probas['binary'][(B, C)][A]\n",
    "                        if prob > scores[begin][end].get(A, -np.inf):\n",
    "                            scores[begin][end][A] = prob\n",
    "                            back[begin][end][dict_non_terminals_indices[A]] = (split, B, C)\n",
    "                            if A in B_binary:\n",
    "                                Bs_scores[begin][end].add(A)\n",
    "\n",
    "                            if A in C_binary:\n",
    "                                Cs_scores[begin][end].add(A)\n",
    "                                \n",
    "    return scores, back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtrack : Build parse tree from CYK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_in_grammar(sentence):\n",
    "    string = '( (Not-inGrammar '\n",
    "    for i in range(len(sentence)-1):\n",
    "        string += '(Not-in-Grammar ' + sentence[i] + ')'\n",
    "        \n",
    "    string += '(Not-in-Grammar ' + sentence[-1] + ')))'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parentheses(back_track, scores, sentence):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Build the parse tree from tha back_track return of CYK algorithm as a string with parentheses. Then if we want to get the parse\n",
    "    in a tree form, we can simply use function Tree.from_string of nltk package.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    back_track : 3D matrix in the form of list of lists, of \"shape\" (n, n, r).\n",
    "                 - n : the length of the sentence we want to parse.\n",
    "                 - r : the number of non terminal nodes in our grammar.\n",
    "                 \n",
    "    Returns\n",
    "    ---------------\n",
    "    String, the string form with parentheses of the parse tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    q = queue.LifoQueue()\n",
    "    begin = 0\n",
    "    end = len(back_track[0]) - 1\n",
    "    starts_scores = []\n",
    "    for start in starts:\n",
    "        starts_scores.append((scores[begin][end].get(start,-np.inf), start))\n",
    "    \n",
    "    starts_scores.sort(reverse=True)\n",
    "    if starts_scores[0][0] == -np.inf:\n",
    "        return not_in_grammar(sentence)\n",
    "    \n",
    "    sent = starts_scores[0][1]\n",
    "    string = '('\n",
    "    q.put((None, sent, 'start', 1, [begin, end]))\n",
    "\n",
    "    while not q.empty():\n",
    "        split, symbol, status, depth, border = q.get()   # border is begin for left and end for right\n",
    "        string += ' (' + symbol\n",
    "\n",
    "        if status == 'left':\n",
    "            border = [border[0], split]\n",
    "            children = back_track[border[0]][border[1]][dict_non_terminals_indices[symbol]]\n",
    "\n",
    "        elif status == 'right':\n",
    "            border = [split, border[1]]\n",
    "            children = back_track[border[0]][border[1]][dict_non_terminals_indices[symbol]]\n",
    "\n",
    "        elif status == 'start':\n",
    "            children = back_track[border[0]][border[1]][dict_non_terminals_indices[symbol]]\n",
    "\n",
    "        if children is not None:\n",
    "            if isinstance(children, grammar.Nonterminal):\n",
    "                node = (split, children, status, depth+1, border)\n",
    "                q.put(node)\n",
    "\n",
    "            elif len(children) == 3:\n",
    "                split, l_child, r_child = children\n",
    "                l_node, r_node = (split, l_child, 'left', 0, border), (split, r_child, 'right', depth+1, border)\n",
    "                q.put(r_node)\n",
    "                q.put(l_node)\n",
    "\n",
    "        else:\n",
    "            depth += 1\n",
    "            word = sentence[border[0]:border[1]][0]\n",
    "            string += ' ' + word + ')'*depth\n",
    "            \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(true_parse, proposed_parse):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------------\n",
    "    Evaluate a proposed parse given the true one, this function prints recall and precision of the whole parse and on POS tags only also.\n",
    "    \n",
    "    Parameters\n",
    "    -----------------\n",
    "    true_parse, proposed_parse : Bracketed strings, the true and proposed parse trees.\n",
    "    \n",
    "    Returns\n",
    "    -----------------\n",
    "    \"\"\"\n",
    "    \n",
    "    true_parse = true_parse[2:-1]\n",
    "    proposed_parse= proposed_parse[2:-1]\n",
    "    \n",
    "    gold_tree = parser.create_from_bracket_string(true_parse)\n",
    "    test_tree = parser.create_from_bracket_string(proposed_parse)\n",
    "    \n",
    "    # Compute recall and precision for POS tags\n",
    "    y_true = np.array(gold_tree.poss)\n",
    "    y_pred = np.array(test_tree.poss)\n",
    "\n",
    "    y_pred = (y_true == y_pred).astype(int)\n",
    "    y_true = np.ones(len(y_true)).astype(int)\n",
    "\n",
    "    (POS_precision, POS_recall, POS_f_score, beta) = precision_recall_fscore_support(y_true,y_pred, labels=[1])\n",
    "    \n",
    "    # Compute recall and precision for the whole parse\n",
    "    thescorer = scorer.Scorer() \n",
    "    result = thescorer.score_trees(gold_tree, test_tree)\n",
    "    \n",
    "    print('Parse recall : {:.2f}%'.format(result.recall*100))\n",
    "    print('Parse precision : {:.2f}%'.format(result.prec*100), end=\"\\n\\n\")\n",
    "    \n",
    "    print('POS recall : {:.2f}%'.format(POS_recall[0]*100))\n",
    "    print('POS precision : {:.2f}%'.format(POS_precision[0]*100))\n",
    "\n",
    "    return result.recall*100, result.prec*100, POS_recall[0]*100, POS_precision[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOV module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, embeddings = pkl.load(open('polyglot-fr.pkl', 'rb'), encoding = 'latin')\n",
    "dict_words_embeddings = dict((word, embedding) for word, embedding in zip(words, embeddings))\n",
    "words_polyglot = set(words) # Set of all the words in polyglot dataset.\n",
    "dict_terminals_embeddings = {terminal : embedding for (terminal, embedding) in dict_words_embeddings.items() if terminal in terminals} # dictionnary mapping terminals to embeddings\n",
    "terminals_embedded = set(dict_terminals_embeddings.keys()) # Set of all terminals having an embedding.\n",
    "lower_case = lambda s : s.lower()\n",
    "terminals_lower = set(map(lower_case, terminals))\n",
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'femme'),\n",
       " (0.13840019702911377, 'mère'),\n",
       " (0.2212699055671692, 'sorcière'),\n",
       " (0.22470712661743164, 'dame'),\n",
       " (0.23393511772155762, 'fille'),\n",
       " (0.2370111346244812, 'chanteuse'),\n",
       " (0.2375941276550293, 'reine'),\n",
       " (0.24107229709625244, 'personne'),\n",
       " (0.24143099784851074, 'sœur'),\n",
       " (0.24942022562026978, 'princesse')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_original = 'femme'\n",
    "scores = []\n",
    "for word in dict_words_embeddings:\n",
    "    scores.append((distance.cosine(dict_words_embeddings[word_original], dict_words_embeddings[word]), word))\n",
    "    \n",
    "sorted(scores)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Computes the Levenshtein distance between two strings.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    s1, s2 : The two strings we want to compare.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    Float, the Levenshtein distance between s1 and s2\n",
    "    \"\"\"\n",
    "    \n",
    "    n1, n2 = len(s1), len(s2)\n",
    "    lev = np.zeros((n1 + 1, n2 + 1))\n",
    "    for i in range(n1 + 1):\n",
    "        lev[i, 0] = i\n",
    "        \n",
    "    for j in range(n2 + 1):\n",
    "        lev[0, j] = j\n",
    "        \n",
    "    for i in range(1, n1 + 1):\n",
    "        for j in range(1, n2 + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                lev[i, j] = min(lev[i-1, j] + 1, lev[i, j-1] + 1, lev[i-1, j-1])\n",
    "                \n",
    "            else:\n",
    "                lev[i, j] = min(lev[i-1, j] + 1, lev[i, j-1] + 1, lev[i-1, j-1] + 1)\n",
    "                \n",
    "    return lev[n1, n2]\n",
    "\n",
    "def damerau_levenshtein(s1, s2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Computes the Damerau-Levenshtein distance between two strings.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    s1, s2 : The two strings we want to compare.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    Float, the Damerau-Levenshtein distance between s1 and s2\n",
    "    \"\"\"\n",
    "    \n",
    "    s1, s2 = s1.lower(), s2.lower()\n",
    "    n1, n2 = len(s1), len(s2)\n",
    "    alphabet = ['!', '\"', '#', '$', '%', '&', '(', ')', \"'\", '*', '+', \n",
    "                ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', \n",
    "                '[', ']', '^', '_', '`', '{', '|', '}', '~', ' ', '°',\n",
    "                'é', 'è', 'ë', 'ê', 'à', 'á', 'â', 'ä', 'ç', 'î', 'ï', \n",
    "                'ô', 'ó', 'ö', 'ù', 'û', 'ß', '©', '±', 'µ', '½'] + [str(i) for i in range(10)] + ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    for char in s1 + s2:\n",
    "        if char not in alphabet:\n",
    "            return 10\n",
    "        \n",
    "    dict_alphabet_indices = {char:index for (index, char) in zip(range(len(alphabet)), alphabet)}\n",
    "    da, d = np.zeros(len(alphabet)).astype(np.int8), np.zeros((n1 + 2, n2 + 2)).astype(np.int8)\n",
    "    maxdist = n1 + n2\n",
    "    d[0, 0] = maxdist\n",
    "    for i in range(n1 + 1):\n",
    "        d[i+1, 0] = maxdist\n",
    "        d[i+1, 1] = i\n",
    "        \n",
    "    for j in range(n2 + 1):\n",
    "        d[0, j+1] = maxdist\n",
    "        d[1, j+1] = j\n",
    "        \n",
    "    for i in range(1, n1 + 1):\n",
    "        db = 0\n",
    "        for j in range(1, n2 + 1):\n",
    "            k = da[dict_alphabet_indices[s2[j-1]]]\n",
    "            l = db\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                cost = 0\n",
    "                db = j\n",
    "                \n",
    "            else:\n",
    "                cost = 1\n",
    "                \n",
    "            d[i+1, j+1] = min(d[i, j] + cost, d[i+1, j] + 1, \n",
    "                              d[i, j+1] + 1, d[k, l] + (i-k-1)+1+(j-l-1))\n",
    "            da[dict_alphabet_indices[s1[i-1]]] = i\n",
    "            \n",
    "    return d[-1, -1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Compute a unigram model from the corpus data.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    data : List of bracketed strings\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    np.array of shape (#words_in_data,) containing the probabilities p(word).\n",
    "    \"\"\"\n",
    "  \n",
    "    probas = np.zeros(len(terminals))\n",
    "    for bracketed in data:\n",
    "        t = Tree.fromstring(bracketed)\n",
    "        for word in t.leaves():\n",
    "            probas[dict_terminals_indices[word]] += 1\n",
    "\n",
    "    return probas/probas.sum()\n",
    "\n",
    "def bigram(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Compute a bigram model from the corpus data.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    data : List of bracketed strings\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    np.array of shape (#words_in_data, #words_in_data) containing the probabilities p(word_current|word_previous).\n",
    "    \"\"\"\n",
    "  \n",
    "    probas = np.full((len(terminals), len(terminals)), 1e-50)\n",
    "    for bracketed in data:\n",
    "        t = Tree.fromstring(bracketed)\n",
    "        sentence = t.leaves()\n",
    "        if len(sentence) >= 2:\n",
    "            for i in range(1, len(sentence)):\n",
    "                index_1 = dict_terminals_indices[sentence[i - 1]] # The previous word in the sequene.\n",
    "                index_2 = dict_terminals_indices[sentence[i]] # The current word in the sequene.\n",
    "                probas[index_1, index_2] += 1\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return probas/((probas.sum(axis = 1).reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_unigram, probas_bigram = unigram(data), bigram(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning OOV words to the training lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7455"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terminals_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9632"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_formal(s, terminals, n_words = 5, swap = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Get the terminals within a lower Damerau-Levenshtein (or Levenshtein) distance of thresh to the word s.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    s         : String, the oov word\n",
    "    terminals : Set of words we have in our corpus.\n",
    "    thresh    : Int, the threshold of Damerau-Levenshtein distance.\n",
    "    swap      : Boolean, True  : Use Damerau-Levenshtein distance.\n",
    "                         False : Use Levenshtein distance\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    Dictionnary of the closest words.\n",
    "        keys   : words in terminals.\n",
    "        values : distance(s, word)\n",
    "    \"\"\"\n",
    "    \n",
    "    if swap:\n",
    "        fun = lambda word : damerau_levenshtein(s, word)\n",
    "        \n",
    "    else:\n",
    "        fun = lambda word : levenshtein(s, word)\n",
    "    return {word : score for score, word in sorted(zip(list(map(fun, terminals)), terminals))[:n_words]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_embedding(s, terminals, n_words = 10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Get the terminals within a lower Damerau-Levenshtein (or Levenshtein) distance of thresh to the word s.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    s         : String, oov word\n",
    "    terminals : Set of words we have in our corpus.\n",
    "    n_words   : Int, number of closest words to s.\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    Dictionnary of the closest words.\n",
    "        keys   : words in terminals.\n",
    "        values : cosine_distance(s, word)\n",
    "    \"\"\"\n",
    "    \n",
    "    fun = lambda word : distance.cosine(dict_words_embeddings[s], dict_terminals_embeddings[word])\n",
    "    return {score_word[1] : score_word[0] for score_word in sorted(zip(map(fun, terminals_embedded), terminals_embedded))[:n_words]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_words(sentence, terminals, probas_unigram, probas_bigram, swap = True, n_words = 10, n_words_formal = 5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------------\n",
    "    Given a word s of the sentence, start by checking if it is in the training lexique, if not then choose a similar word \n",
    "    from the lexique using the formal and embedding similarities and a bigram language model trained on the training corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ---------------\n",
    "    sentence       : List of strings containing tokens of a sentence.\n",
    "    terminals      : Set of all words in the training corpus.\n",
    "    probas_unigram : 1D np.array of shape (len(terminals),), unigram model trained on the training corpus.\n",
    "    probas_bigram  : 2D np.array of shape (len(terminals), len(terminals)), bigram model trained on the training corpus.\n",
    "    thresh, swap,  : Parameters of closest_formal (see its doc).\n",
    "    n_words        : Parameters of closest_embedding (see its doc).\n",
    "    \n",
    "    Returns\n",
    "    ---------------\n",
    "    List of strings containing the closest words to the sentence from the training corpus.\n",
    "    \"\"\"\n",
    "    \n",
    "    log_proba = 0\n",
    "    sent = sentence.copy()\n",
    "    for i in range(len(sent)):\n",
    "        s = sent[i]\n",
    "        if s in terminals:\n",
    "            log_proba += math.log(probas_unigram[dict_terminals_indices[s]]) if i==0 else math.log(probas_bigram[dict_terminals_indices[sent[i-1]], dict_terminals_indices[s]])\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            words_formal = closest_formal(s, terminals, n_words_formal, swap)\n",
    "            words_embedding = closest_embedding(s, terminals, n_words) if s in dict_words_embeddings else {}\n",
    "            words_proposed = set(words_formal.keys()) | set(words_embedding.keys()) # Set of the proposed words\n",
    "            if i == 0:\n",
    "                scores = []\n",
    "                for word in words_proposed:\n",
    "                    unigram = math.log(probas_unigram[dict_terminals_indices[word]])\n",
    "                    scores.append((unigram, word))\n",
    "                \n",
    "            else:\n",
    "                scores = []\n",
    "                for word in words_proposed:\n",
    "                    bigram = 0.8*math.log(probas_bigram[dict_terminals_indices[sent[i-1]], dict_terminals_indices[word]]) + 0.2*math.log(probas_unigram[dict_terminals_indices[word]])\n",
    "                    score = log_proba + bigram\n",
    "                    scores.append((score, word))\n",
    "                \n",
    "            scores.sort(reverse = True)\n",
    "            sent[i] = scores[0][1]\n",
    "            log_proba += scores[0][0]\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test_sentences\n",
    "# file = open(\"test_data\", 'w', encoding='utf-8')\n",
    "# for i in range(len(data_test_sentences)-1):\n",
    "#     file.write(data_test_sentences[i]+'\\n')\n",
    "    \n",
    "# file.write(data_test_sentences[-1])\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data', 'r', encoding = 'utf-8') as file:\n",
    "    data_test_sentences = file.read().splitlines()\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    sentence_oov = choose_words(sentence, terminals, probas_unigram, probas_bigram, n_words_formal=2, n_words=20, swap=False)\n",
    "    scores, back = cyk(sentence_oov)\n",
    "    bracketed = build_parentheses(back, scores, sentence)\n",
    "    t_test = Tree.fromstring(bracketed)\n",
    "    t_test.un_chomsky_normal_form()\n",
    "    return \" \".join(str(t_test).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_sentences = []\n",
    "for bracketed in data_test:a:\n",
    "    t = Tree.fromstring(bracketed)\n",
    "    data_test_sentences.append(\" \".join(t.leaves()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "1066.7555146217346\n"
     ]
    }
   ],
   "source": [
    "parses = []\n",
    "start_time = time()\n",
    "i=0\n",
    "for sentence in data_test_sentences:\n",
    "    parses.append(parse(sentence))\n",
    "    i+=1\n",
    "    if i%50 == 0:\n",
    "        print(i)\n",
    "    \n",
    "print(time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse recall : 61.54%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 91.30%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 83.33%\n",
      "Parse precision : 76.92%\n",
      "\n",
      "POS recall : 95.65%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 86.67%\n",
      "Parse precision : 86.67%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 82.61%\n",
      "Parse precision : 70.37%\n",
      "\n",
      "POS recall : 89.47%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 84.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 81.25%\n",
      "Parse precision : 72.22%\n",
      "\n",
      "POS recall : 88.89%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 53.33%\n",
      "Parse precision : 54.55%\n",
      "\n",
      "POS recall : 96.61%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 47.83%\n",
      "Parse precision : 47.83%\n",
      "\n",
      "POS recall : 93.10%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 44.68%\n",
      "Parse precision : 42.00%\n",
      "\n",
      "POS recall : 96.10%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 58.82%\n",
      "Parse precision : 47.62%\n",
      "\n",
      "POS recall : 82.69%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 40.00%\n",
      "\n",
      "POS recall : 76.47%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 84.62%\n",
      "Parse precision : 81.48%\n",
      "\n",
      "POS recall : 97.06%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 47.62%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 42.11%\n",
      "Parse precision : 34.78%\n",
      "\n",
      "POS recall : 86.96%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 87.50%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 30.43%\n",
      "Parse precision : 26.92%\n",
      "\n",
      "POS recall : 82.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 71.43%\n",
      "Parse precision : 71.43%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 73.91%\n",
      "Parse precision : 70.83%\n",
      "\n",
      "POS recall : 97.37%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.96%\n",
      "Parse precision : 54.84%\n",
      "\n",
      "POS recall : 88.10%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 55.56%\n",
      "\n",
      "POS recall : 94.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 51.61%\n",
      "Parse precision : 47.06%\n",
      "\n",
      "POS recall : 91.30%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 45.45%\n",
      "Parse precision : 37.04%\n",
      "\n",
      "POS recall : 93.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 91.67%\n",
      "\n",
      "POS recall : 94.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 40.00%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 80.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 82.14%\n",
      "Parse precision : 67.65%\n",
      "\n",
      "POS recall : 78.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 40.74%\n",
      "Parse precision : 39.29%\n",
      "\n",
      "POS recall : 89.19%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 83.33%\n",
      "Parse precision : 71.43%\n",
      "\n",
      "POS recall : 88.46%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 85.71%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.82%\n",
      "Parse precision : 50.82%\n",
      "\n",
      "POS recall : 95.56%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 78.57%\n",
      "Parse precision : 73.33%\n",
      "\n",
      "POS recall : 91.43%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 58.82%\n",
      "\n",
      "POS recall : 92.59%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 70.97%\n",
      "Parse precision : 68.75%\n",
      "\n",
      "POS recall : 93.88%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 45.00%\n",
      "Parse precision : 40.91%\n",
      "\n",
      "POS recall : 86.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 90.00%\n",
      "Parse precision : 90.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 55.56%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 78.57%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 77.78%\n",
      "Parse precision : 70.00%\n",
      "\n",
      "POS recall : 92.86%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 88.89%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 71.43%\n",
      "Parse precision : 71.43%\n",
      "\n",
      "POS recall : 91.30%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 70.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 88.89%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 72.73%\n",
      "Parse precision : 74.42%\n",
      "\n",
      "POS recall : 94.23%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 85.00%\n",
      "Parse precision : 89.47%\n",
      "\n",
      "POS recall : 92.86%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 86.67%\n",
      "Parse precision : 81.25%\n",
      "\n",
      "POS recall : 95.24%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 65.12%\n",
      "Parse precision : 65.12%\n",
      "\n",
      "POS recall : 96.72%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 53.57%\n",
      "\n",
      "POS recall : 86.05%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 92.31%\n",
      "Parse precision : 92.31%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 93.75%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 95.24%\n",
      "Parse precision : 95.24%\n",
      "\n",
      "POS recall : 93.55%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 83.33%\n",
      "Parse precision : 71.43%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 84.62%\n",
      "Parse precision : 84.62%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 91.67%\n",
      "Parse precision : 91.67%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 96.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 56.25%\n",
      "Parse precision : 52.94%\n",
      "\n",
      "POS recall : 93.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 92.86%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 44.00%\n",
      "\n",
      "POS recall : 87.10%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 95.24%\n",
      "Parse precision : 95.24%\n",
      "\n",
      "POS recall : 93.55%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 86.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 69.23%\n",
      "Parse precision : 64.29%\n",
      "\n",
      "POS recall : 91.89%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 85.00%\n",
      "Parse precision : 80.95%\n",
      "\n",
      "POS recall : 90.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 86.67%\n",
      "Parse precision : 81.25%\n",
      "\n",
      "POS recall : 91.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 92.31%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 64.29%\n",
      "Parse precision : 56.25%\n",
      "\n",
      "POS recall : 84.44%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 73.33%\n",
      "Parse precision : 68.75%\n",
      "\n",
      "POS recall : 95.65%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 68.18%\n",
      "Parse precision : 62.50%\n",
      "\n",
      "POS recall : 97.06%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 78.95%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 91.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 62.50%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 83.33%\n",
      "\n",
      "POS recall : 75.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 85.71%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 50.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 32.26%\n",
      "Parse precision : 28.57%\n",
      "\n",
      "POS recall : 80.95%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 90.00%\n",
      "Parse precision : 81.82%\n",
      "\n",
      "POS recall : 93.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 60.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 46.88%\n",
      "Parse precision : 44.12%\n",
      "\n",
      "POS recall : 95.45%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 85.71%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 95.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 52.17%\n",
      "\n",
      "POS recall : 90.91%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 33.33%\n",
      "Parse precision : 42.86%\n",
      "\n",
      "POS recall : 90.91%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 28.57%\n",
      "Parse precision : 22.22%\n",
      "\n",
      "POS recall : 86.96%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 92.86%\n",
      "Parse precision : 68.42%\n",
      "\n",
      "POS recall : 72.22%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 41.67%\n",
      "Parse precision : 45.45%\n",
      "\n",
      "POS recall : 91.18%\n",
      "POS precision : 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse recall : 40.62%\n",
      "Parse precision : 40.62%\n",
      "\n",
      "POS recall : 93.02%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 56.25%\n",
      "Parse precision : 52.94%\n",
      "\n",
      "POS recall : 84.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 62.50%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 52.38%\n",
      "Parse precision : 47.83%\n",
      "\n",
      "POS recall : 88.57%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 72.73%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 74.07%\n",
      "\n",
      "POS recall : 83.78%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 93.33%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 89.47%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 44.44%\n",
      "Parse precision : 46.51%\n",
      "\n",
      "POS recall : 87.72%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 95.45%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 50.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 44.44%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 84.21%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 86.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 82.35%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 81.25%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 81.82%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 80.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 25.00%\n",
      "Parse precision : 20.00%\n",
      "\n",
      "POS recall : 75.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 40.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 63.64%\n",
      "Parse precision : 63.64%\n",
      "\n",
      "POS recall : 98.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 47.83%\n",
      "Parse precision : 45.83%\n",
      "\n",
      "POS recall : 93.18%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 40.74%\n",
      "Parse precision : 37.93%\n",
      "\n",
      "POS recall : 94.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 56.52%\n",
      "Parse precision : 52.00%\n",
      "\n",
      "POS recall : 96.77%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 86.36%\n",
      "Parse precision : 86.36%\n",
      "\n",
      "POS recall : 92.86%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 37.50%\n",
      "Parse precision : 37.50%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 60.87%\n",
      "Parse precision : 56.00%\n",
      "\n",
      "POS recall : 97.56%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 55.56%\n",
      "Parse precision : 45.45%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 59.09%\n",
      "Parse precision : 55.32%\n",
      "\n",
      "POS recall : 94.44%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 15.38%\n",
      "Parse precision : 14.29%\n",
      "\n",
      "POS recall : 86.36%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 91.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 90.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 63.33%\n",
      "Parse precision : 59.38%\n",
      "\n",
      "POS recall : 94.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 64.29%\n",
      "Parse precision : 56.25%\n",
      "\n",
      "POS recall : 93.02%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 33.33%\n",
      "Parse precision : 27.27%\n",
      "\n",
      "POS recall : 86.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 81.82%\n",
      "Parse precision : 81.82%\n",
      "\n",
      "POS recall : 82.35%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 69.57%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 97.14%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 96.00%\n",
      "\n",
      "POS recall : 91.18%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 58.82%\n",
      "\n",
      "POS recall : 96.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 76.92%\n",
      "Parse precision : 76.92%\n",
      "\n",
      "POS recall : 95.45%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 83.33%\n",
      "\n",
      "POS recall : 80.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 83.33%\n",
      "Parse precision : 62.50%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 60.87%\n",
      "Parse precision : 56.00%\n",
      "\n",
      "POS recall : 89.29%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 95.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 34.38%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 88.37%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 75.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 21.74%\n",
      "Parse precision : 21.74%\n",
      "\n",
      "POS recall : 97.06%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 41.18%\n",
      "Parse precision : 41.18%\n",
      "\n",
      "POS recall : 82.61%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 81.82%\n",
      "Parse precision : 81.82%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 64.29%\n",
      "Parse precision : 60.00%\n",
      "\n",
      "POS recall : 94.12%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 58.62%\n",
      "Parse precision : 54.84%\n",
      "\n",
      "POS recall : 90.24%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 40.00%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 75.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 47.62%\n",
      "Parse precision : 47.62%\n",
      "\n",
      "POS recall : 92.86%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 83.33%\n",
      "Parse precision : 90.91%\n",
      "\n",
      "POS recall : 82.35%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 88.89%\n",
      "\n",
      "POS recall : 85.71%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 88.89%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 88.89%\n",
      "Parse precision : 86.49%\n",
      "\n",
      "POS recall : 94.34%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 77.78%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 80.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 57.14%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 54.55%\n",
      "Parse precision : 46.15%\n",
      "\n",
      "POS recall : 87.23%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 62.50%\n",
      "Parse precision : 58.82%\n",
      "\n",
      "POS recall : 90.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 65.22%\n",
      "\n",
      "POS recall : 87.10%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 47.22%\n",
      "Parse precision : 39.53%\n",
      "\n",
      "POS recall : 81.13%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 55.56%\n",
      "Parse precision : 62.50%\n",
      "\n",
      "POS recall : 96.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 64.71%\n",
      "Parse precision : 57.89%\n",
      "\n",
      "POS recall : 92.59%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 40.00%\n",
      "Parse precision : 31.25%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 33.33%\n",
      "Parse precision : 30.95%\n",
      "\n",
      "POS recall : 90.91%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 46.15%\n",
      "Parse precision : 37.50%\n",
      "\n",
      "POS recall : 86.36%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 28.57%\n",
      "\n",
      "POS recall : 62.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 16.67%\n",
      "Parse precision : 9.09%\n",
      "\n",
      "POS recall : 52.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 25.00%\n",
      "Parse precision : 16.67%\n",
      "\n",
      "POS recall : 50.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 25.00%\n",
      "\n",
      "POS recall : 80.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 40.00%\n",
      "\n",
      "POS recall : 60.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 33.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 25.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 50.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 87.50%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 28.57%\n",
      "Parse precision : 30.77%\n",
      "\n",
      "POS recall : 86.21%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 33.33%\n",
      "Parse precision : 31.25%\n",
      "\n",
      "POS recall : 89.66%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 54.55%\n",
      "\n",
      "POS recall : 75.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 43.75%\n",
      "Parse precision : 36.84%\n",
      "\n",
      "POS recall : 82.61%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 37.50%\n",
      "Parse precision : 27.27%\n",
      "\n",
      "POS recall : 77.27%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 45.45%\n",
      "\n",
      "POS recall : 81.82%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 50.00%\n",
      "Parse precision : 42.86%\n",
      "\n",
      "POS recall : 88.89%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 80.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 61.54%\n",
      "Parse precision : 59.26%\n",
      "\n",
      "POS recall : 90.62%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 55.88%\n",
      "Parse precision : 52.78%\n",
      "\n",
      "POS recall : 93.88%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 30.00%\n",
      "Parse precision : 31.58%\n",
      "\n",
      "POS recall : 88.46%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 56.52%\n",
      "Parse precision : 44.83%\n",
      "\n",
      "POS recall : 84.21%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 55.00%\n",
      "Parse precision : 55.00%\n",
      "\n",
      "POS recall : 96.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 55.56%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 91.43%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 68.18%\n",
      "Parse precision : 68.18%\n",
      "\n",
      "POS recall : 89.29%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 58.62%\n",
      "Parse precision : 58.62%\n",
      "\n",
      "POS recall : 97.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 93.33%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 95.24%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 59.09%\n",
      "Parse precision : 53.06%\n",
      "\n",
      "POS recall : 92.54%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 37.21%\n",
      "Parse precision : 32.65%\n",
      "\n",
      "POS recall : 81.36%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 63.16%\n",
      "Parse precision : 52.17%\n",
      "\n",
      "POS recall : 84.62%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 53.85%\n",
      "Parse precision : 46.67%\n",
      "\n",
      "POS recall : 82.35%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 58.33%\n",
      "Parse precision : 50.00%\n",
      "\n",
      "POS recall : 83.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 57.14%\n",
      "Parse precision : 54.55%\n",
      "\n",
      "POS recall : 93.33%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 38.46%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 82.61%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 26.32%\n",
      "Parse precision : 25.00%\n",
      "\n",
      "POS recall : 85.19%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 66.67%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 96.30%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 60.00%\n",
      "Parse precision : 60.00%\n",
      "\n",
      "POS recall : 94.74%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 0.00%\n",
      "Parse precision : 0.00%\n",
      "\n",
      "POS recall : 0.00%\n",
      "POS precision : 0.00%\n",
      "Parse recall : 33.33%\n",
      "Parse precision : 33.33%\n",
      "\n",
      "POS recall : 95.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 52.63%\n",
      "Parse precision : 43.48%\n",
      "\n",
      "POS recall : 77.14%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 38.46%\n",
      "Parse precision : 25.00%\n",
      "\n",
      "POS recall : 70.37%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 87.50%\n",
      "\n",
      "POS recall : 84.62%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 66.67%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 75.00%\n",
      "Parse precision : 75.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 80.00%\n",
      "Parse precision : 66.67%\n",
      "\n",
      "POS recall : 90.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n",
      "Parse recall : 100.00%\n",
      "Parse precision : 100.00%\n",
      "\n",
      "POS recall : 100.00%\n",
      "POS precision : 100.00%\n"
     ]
    }
   ],
   "source": [
    "parse_recalls, parse_precisions, pos_recalls, pos_precisions = [], [], [], []\n",
    "for i in range(len(parses)):\n",
    "    parse_recall, parse_precision, pos_recall, pos_precision = score('( ' + ignore_functional_labels(data_test[i]) + ')', parses[i])\n",
    "    parse_recalls.append(parse_recall)\n",
    "    parse_precisions.append(parse_precision)\n",
    "    pos_recalls.append(pos_recall)\n",
    "    pos_precisions.append(pos_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.02030130759158\n",
      "56.725795538229804\n",
      "74.55492158314429\n",
      "83.54838709677419\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(parse_recalls))\n",
    "print(np.mean(parse_precisions))\n",
    "print(np.mean(pos_recalls))\n",
    "print(np.mean(pos_precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"evaluation_data.parser_output\", 'w', encoding='utf-8')\n",
    "# for i in range(len(parses)-1):\n",
    "#     file.write(parses[i]+'\\n')\n",
    "    \n",
    "# file.write(parses[-1])\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
